# R√©ponses √† la Section 10: Explore Other Gemini Models

## Instructions du README

La section 10 demande de:
1. Tester diff√©rents mod√®les Gemini (`gemini-flash-latest`, `gemini-2.5-pro`, `gemini-2.5-flash-lite`)
2. Noter les observations sur:
   - **Response length** (longueur des r√©ponses)
   - **CWE coverage** (couverture CWE)
   - **Refusal behavior** (comportement de refus)
3. Utiliser ces observations pour la section "Observations"

---

## Comment G√©n√©rer les Baselines pour Tous les Mod√®les

### M√©thode 1: PowerShell (Recommand√©e)

Depuis la racine du projet (`C:\llm-cybesecurity-labs-project\starter-labs\llm-sec-lab1-starter\llm-sec-lab1`):

```powershell
# 1. gemini-flash-latest
$env:MODEL_ID="gemini-flash-latest"
python -m src.app
Copy-Item reports\baseline.json reports\baseline_gemini-flash-latest.json
Write-Host  Baseline g√©n√©r√© pour gemini-flash-latest"

# 2. gemini-2.5-pro
$env:MODEL_ID="gemini-2.5-pro"
python -m src.app
Copy-Item reports\baseline.json reports\baseline_gemini-2.5-pro.json
Write-Host  Baseline g√©n√©r√© pour gemini-2.5-pro"

# 3. gemini-2.5-flash-lite
$env:MODEL_ID="gemini-2.5-flash-lite"
python -m src.app
Copy-Item reports\baseline.json reports\baseline_gemini-2.5-flash-lite.json
Write-Host  Baseline g√©n√©r√© pour gemini-2.5-flash-lite"

# 4. gemini-2.5-flash (explicite, pour comparaison)
$env:MODEL_ID="gemini-2.5-flash"
python -m src.app
Copy-Item reports\baseline.json reports\baseline_gemini-2.5-flash.json
Write-Host  Baseline g√©n√©r√© pour gemini-2.5-flash"
```

### M√©thode 2: Via le Notebook Jupyter

Dans `notebooks/lab1_live_run.ipynb`, ajoute une cellule pour chaque mod√®le:

```python
import os
os.environ["MODEL_ID"] = "gemini-flash-latest"  # Change pour chaque mod√®le
from src import app
app.main()
```

Puis copie manuellement `reports/baseline.json` vers le nom appropri√©.

---

## Comment Analyser et Comparer les Mod√®les

### √âtape 1: Ex√©cuter le script d'analyse

```powershell
python analyze_models.py
```

Ce script g√©n√®re automatiquement:
- Un tableau comparatif des m√©triques
- Des d√©tails pour chaque mod√®le
- Un rapport markdown dans `reports/model_analysis_report.md`

### √âtape 2: Examiner les m√©triques cl√©s

Pour chaque mod√®le, note:

1. **Response Length (Longueur des r√©ponses)**
   - Regarde la colonne "Long. Rationale" dans le tableau
   - Compare avec les autres mod√®les
   - Plus long = plus d√©taill√© mais plus cher

2. **CWE Coverage (Couverture CWE)**
   - Regarde la colonne "CWE Uniques"
   - Compare le nombre de CWE diff√©rents d√©tect√©s
   - Plus de CWE = meilleure d√©tection de divers types de vuln√©rabilit√©s

3. **Refusal Behavior (Comportement de refus)**
   - Regarde la colonne "Refus"
   - Compare le nombre de refus explicites
   - Plus de refus = meilleure r√©sistance aux attaques

---

## Observations Bas√©es sur le Mod√®le Actuel (gemini-2.5-flash)

### M√©triques Observ√©es

- **Findings par prompt**: 1.64 (moyenne)
- **Longueur moyenne des rationales**: 476 caract√®res
- **CWE uniques d√©tect√©s**: 13
- **Refus explicites**: 7 sur 11 prompts (63.6%)
- **Risques LLM couverts**: LLM01, LLM02, LLM03, LLM04, LLM06, LLM08, LLM09, LLM10

### Points Forts
 **Bonne couverture CWE**: 13 CWE diff√©rents d√©tect√©s, couvrant un large √©ventail de vuln√©rabilit√©s **Refus explicites**: 7 refus d√©tect√©s sur les prompts malveillants **Rationales d√©taill√©es**: 476 caract√®res en moyenne, explications compl√®tes **D√©tection compl√®te**: Tous les risques OWASP LLM Top 10 pertinents sont d√©tect√©s

### Points √† Am√©liorer

‚ö†Ô∏è Certains prompts l√©gitimes g√©n√®rent des findings (overreliance d√©tect√©e, ce qui est correct mais peut √™tre consid√©r√© comme "trop strict")
‚ö†Ô∏è Rationales parfois longues (impact sur les co√ªts API)

---

## Comparaison Attendue avec les Autres Mod√®les

### gemini-2.5-pro

**Attentes bas√©es sur la documentation:**
- Rationales plus longues et d√©taill√©es que Flash
- Meilleure couverture CWE
- Refus plus explicites et nuanc√©s
- **Risque**: Peut sous-rapporter sur les prompts b√©nins (retourne findings vides)

**Utilisation recommand√©e**: Quand la qualit√© et la pr√©cision sont prioritaires, avec revue humaine

### gemini-flash-latest

**Attentes bas√©es sur la documentation:**
- Rationales similaires √† Flash mais plus courtes
- Couverture CWE similaire
- Refus efficaces mais moins d√©taill√©s
- **Note**: Peut g√©n√©rer des warnings `thought_signature` mais JSON valide apr√®s nettoyage

**Utilisation recommand√©e**: Bon compromis vitesse/qualit√©

### gemini-2.5-flash-lite

**Attentes bas√©es sur la documentation:**
- Rationales les plus courtes
- D√©cisions similaires √† Flash mais explications r√©duites
- Bon pour budgets serr√©s
- **Risque**: Rationales courtes peuvent √™tre moins claires

**Utilisation recommand√©e**: Quand le co√ªt/latence sont critiques et que les explications courtes sont acceptables

---

## Template pour Documenter Tes Observations

Une fois que tu as g√©n√©r√© tous les baselines, remplis ce template:

```markdown
## Observations sur les Mod√®les Gemini

### 1. Response Length (Longueur des R√©ponses)

| Mod√®le | Longueur Moyenne | Observation |
|--------|------------------|-------------|
| gemini-2.5-flash | 476 chars | [Tes observations] |
| gemini-2.5-pro | [X] chars | [Tes observations] |
| gemini-flash-latest | [X] chars | [Tes observations] |
| gemini-2.5-flash-lite | [X] chars | [Tes observations] |

**Conclusion**: [Quel mod√®le a les r√©ponses les plus longues/courtes et pourquoi c'est important]

### 2. CWE Coverage (Couverture CWE)

| Mod√®le | CWE Uniques | CWE les Plus Fr√©quents | Observation |
|--------|-------------|------------------------|-------------|
| gemini-2.5-flash | 13 | CWE-943, CWE-200, CWE-693 | [Tes observations] |
| gemini-2.5-pro | [X] | [Liste] | [Tes observations] |
| gemini-flash-latest | [X] | [Liste] | [Tes observations] |
| gemini-2.5-flash-lite | [X] | [Liste] | [Tes observations] |

**Conclusion**: [Quel mod√®le d√©tecte le plus de types de vuln√©rabilit√©s]

### 3. Refusal Behavior (Comportement de Refus)

| Mod√®le | Refus D√©tect√©s | Exemples de Refus | Observation |
|--------|----------------|-------------------|-------------|
| gemini-2.5-flash | 7/11 | "I refuse to comply", "cannot provide" | [Tes observations] |
| gemini-2.5-pro | [X]/11 | [Exemples] | [Tes observations] |
| gemini-flash-latest | [X]/11 | [Exemples] | [Tes observations] |
| gemini-2.5-flash-lite | [X]/11 | [Exemples] | [Tes observations] |

**Conclusion**: [Quel mod√®le refuse le mieux les tentatives malveillantes]

### Recommandation Finale

**Mod√®le choisi pour ce projet**: [nom du mod√®le]

**Justification**:
- [Raison 1 bas√©e sur les m√©triques]
- [Raison 2 bas√©e sur les m√©triques]
- [Raison 3 bas√©e sur les m√©triques]

**Trade-offs accept√©s**:
- [Ce qu'on gagne]
- [Ce qu'on perd]
```

---

## Commandes Rapides pour Tout Faire d'un Coup

Cr√©e un fichier `generate_all_baselines.ps1`:

```powershell
# Script PowerShell pour g√©n√©rer tous les baselines

$models = @(
    "gemini-flash-latest",
    "gemini-2.5-pro",
    "gemini-2.5-flash-lite",
    "gemini-2.5-flash"
)

foreach ($model in $models) {
    Write-Host "`nüîÑ G√©n√©ration du baseline pour $model..."
    $env:MODEL_ID = $model
    python -m src.app
    $outputFile = "reports\baseline_$model.json"
    Copy-Item reports\baseline.json $outputFile
    Write-Host  Baseline sauvegard√©: $outputFile"
}

Write-Host "`nüìä Analyse des mod√®les..."
python analyze_models.py

Write-Host "` Termin√©! Consulte reports/model_analysis_report.md pour les r√©sultats."
```

Puis ex√©cute:
```powershell
.\generate_all_baselines.ps1
```

---

## Prochaines √âtapes

1. G√©n√®re les baselines pour tous les mod√®les (voir commandes ci-dessus)
2. Ex√©cute `python analyze_models.py` pour obtenir les m√©triques
3. Compare les r√©sultats dans les tableaux g√©n√©r√©s
4. Remplis le template d'observations ci-dessus
5. Int√®gre tes observations dans la section "Observations" de ton rapport final

